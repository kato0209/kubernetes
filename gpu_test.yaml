# Service configuration for multinode.
apiVersion: v1
kind: Service
metadata:
  name: multinode-svc
spec:
  clusterIP: None  # ClusterIP set to None for headless service.
  ports:
  - name: nccl  # Port for torchrun master-worker node communication.
    port: 29500
    targetPort: 29500
  selector:
    job-name: multinode-job  # Selector for pods associated with this service.

apiVersion: batch/v1
kind: Job
metadata:
  name: multinode-job
spec:
  completionMode: Indexed
  completions: 1
  parallelism: 1
  template:
    spec:
      containers:
      - image: kato0209/gpu_test:latest
        name: gpu-container
        env:
        - name: MASTER_ADDR
          value: multinode-job-0.wokwok.default.svc.cluster.local  # Node with rank 0 is chosen as the master node.
        - name: MASTER_PORT
          value: '29500'
        - name: NNODES
          value: '1'  # Number of training nodes.
        - name: NGPUS
          value: '1'  # Number of GPUs in the machine.
        ports:
        - containerPort: 29500
          name: nccl
        command: ["sh", "-c", "python -m torch.distributed.launch --nnodes=$NNODES --node_rank=$JOB_COMPLETION_INDEX --nproc_per_node=$NGPUS example.py"]
        #command: ["sh", "-c", "ls ./; echo 'hello' "]
        resources:
          limits:
            nvidia.com/gpu: 1
      restartPolicy: Never
      subdomain: wokwok  # Required for pod-to-pod communication in Indexed-Jobs.