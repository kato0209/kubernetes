# Service configuration for multinode.
apiVersion: v1
kind: Service
metadata:
  name: multinode-svc
spec:
  clusterIP: None  # ClusterIP set to None for headless service.
  ports:
  - name: nccl  # Port for torchrun master-worker node communication.
    port: 29500
    targetPort: 29500
  selector:
    job-name: multinode-job  # Selector for pods associated with this service.

---

apiVersion: batch/v1
kind: Job
metadata:
  name: multinode-job
spec:
  completionMode: Indexed
  completions: 2
  parallelism: 2
  template:
    spec:
      restartPolicy: Never
      subdomain: multinode-svc  # Subdomain for the headless service.
      containers:
      - image: kato0209/gpu_test:latest
        name: multinode
        env:
        - name: MASTER_ADDR
          value: multinode-job-0.multinode-svc.default.svc.cluster.local  # Node with rank 0 is chosen as the master node.
        - name: MASTER_PORT
          value: '29500'
        - name: NNODES
          value: '2'  # Number of training nodes.
        - name: NGPUS
          value: '1'  # Number of GPUs in the machine.
        ports:
        - containerPort: 29500
          name: nccl
        command:
        - bash
        - -c
        - |
          for i in 0 1 
          do
            gotStatus="-1"
            wantStatus="0"             
            while [ $gotStatus -ne $wantStatus ]
            do                                       
              ping -c 1 multinode-job-${i}.multinode-svc.default.svc.cluster.local > /dev/null 2>&1
              gotStatus=$?                
              if [ $gotStatus -ne $wantStatus ]; then
                echo "Failed to ping pod multinode-job-${i}.multinode-svc, retrying in 1 second..."
                sleep 1
              fi
            done                                                         
            echo "Successfully pinged pod: multinode-job-${i}.multinode-svc"
          done        
        #command: ["sh", "-c", "ls ./; echo 'hello' "]
        resources:
          limits:
            nvidia.com/gpu: 1
